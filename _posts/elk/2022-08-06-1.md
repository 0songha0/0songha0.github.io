---
title: "logstash 수집 방법 / mariadb 수집하여 엘라스틱서치로 output (작성중)"
excerpt: ""

categories:
  - 엘라스틱서치
tags:
  - []

permalink: /elk/2022-08-06-1

toc: true
toc_sticky: true

date: 2022-08-06
last_modified_at: 2022-08-06
---

엘라스틱서치 매핑 종류


동적 매핑 (Dynamic mapping)

logstash로 데이터 수집 시 인덱스가 없다면

- 숫자 : long 타입

- 날짜 : date 타입

- 문자열 : text 타입 + keyword 타입 (멀티 필드)

매핑으로 엘라스틱서치에서 인덱스를 자동 생성해주는 것.



명시적 매핑 (Explicit mapping)

개발자가 미리 인덱스 매핑정보를 정의해두는 것.



인덱스 규모가 커질수록 동적 매핑보다 명시적 매핑이 성능 향상에 좋음







logstash 설정파일 수정


logstash 설정파일 수정

vi /etc/logstash/logstash-sample.conf

기존 소스 (beats 데이터 수집)

input {
  beats {
    port => 5044
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%[+YYYY.MM.dd]"
    #user => "elastic"
    #password => "changeme"
  }
}

참고 소스 (beats 미사용, 키보드 데이터 수집)

input {
  stdin{}
}

filter {
    #데이터 전처리
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "test"
  }
}


미사용 소스 (beats 미사용, DB 데이터 수집, 매번 신규 수집 = 같은 데이터도 계속 수집해서 insert 해버림)

input {
    jdbc {
      jdbc_driver_library => "/usr/share/logstash/tools/mariadb-java-client-3.0.7.jar"
      jdbc_driver_class => "Java::org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://DB서버명:포트/DB명"
      jdbc_user => "유저명"
      jdbc_password => "암호"
      statement => "select * from 테이블명" #쿼리
      schedule => "* * * * *" # 쿼리 스케줄링 : 1분에 1번 (cron 표현식. 분0~59 시0~23 일1~31 월1~12 요일0~6)
    }
}

filter {
    #데이터 전처리
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "인덱스명" # index는 데이터 수집 시 자동으로 생성됨
  }
}


미사용 소스 (beats 미사용, DB 데이터 수집, 마지막 Idx부터 수집)

단점 : 

- DB 데이터가 수정되거나 삭제되어도 엘라스틱서치 인덱스 데이터는 변경되지 않음

- 인덱스 삭제 시 last_run_metadata_path 파일의 last value를 0으로 변경하지 않으면 데이터 수집 안됨 (이전 last value가 저장되어 있기 때문)

- conf 파일 복제 시 신규 conf 파일에서 last_run_metadata_path명 등 반드시 변경해줘야 함 (미수정 시 버그 발생)

수정이 일어나지 않는 로그 파일 수집에나 사용할만한 것 같음

input {
    jdbc {
      jdbc_driver_library => "/usr/share/logstash/tools/mariadb-java-client-3.0.7.jar"
      jdbc_driver_class => "Java::org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://DB서버명:포트/DB명"
      jdbc_user => "유저명"
      jdbc_password => "암호"
      use_column_value => true #true 시 :sql_last_value(마지막 수집 idx 반환) 사용 가능
      tracking_column => "idx" # 유니크한 idx 컬럼으로 마지막 수집 위치 확인
      statement => "select * from 테이블명 where idx > :sql_last_value order by idx ASC" #쿼리 (마지막 수집 위치 다음부터 수집)
      schedule => "* * * * *" # 쿼리 스케줄링 : 1분에 1번 (cron 표현식. 분0~59 시0~23 일1~31 월1~12 요일0~6)
      last_run_metadata_path => "/etc/logstash/last_value/conf파일명.txt" # pipeline으로 여러 conf를 실행하면 :sql_last_value가 공유될 수 있기 때문에 파일에 기록해야 함. 파일에 기록할 경우, 초기값 0이 들어간 파일을 직접 생성하고 sudo chmod 777로 권한을 주지 않으면 Scheduler intercepted an error: {:exception=>Errno::EACCES, :message=>"Permission denied 에러 남
    }
}

filter {
    #데이터 전처리
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "인덱스명" # index는 데이터 수집 시 자동으로 생성됨
    #user => "elastic"
    #password => "암호"
  }
}


사용 소스 (beats 미사용, DB 데이터 수집, 매번 같은 key는 덮어쓰기 insert & update 수집)

단점 :

- 수정 내용이 반영되나 DB에서 삭제된 데이터는 엘라스틱서치 index에서 삭제되지 않음.

그러나 DB 데이터를 직접 DELETE 치지 않고, DELETE YN 컬럼만 변경시킨다 하니 이대로 수집하기로 함.

input {
    jdbc {
      jdbc_driver_library => "/usr/share/logstash/tools/mariadb-java-client-3.0.7.jar"
      jdbc_driver_class => "Java::org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://DB서버명:포트/DB명"
      jdbc_user => "유저명"
      jdbc_password => "암호"
      statement => "select * from 테이블명" #쿼리
      schedule => "* * * * *" # 쿼리 스케줄링 : 1분에 1번 (cron 표현식. 분0~59 시0~23 일1~31 월1~12 요일0~6)
    }
}

filter {
    #데이터 전처리
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "인덱스명" # index는 데이터 수집 시 자동으로 생성됨
    document_id => "%{key컬럼명}" # document의 id로 키 컬럼을 사용하고, 이를 기준으로 insert & update
    #user => "elastic"
    #password => "암호"
  }
}


최종 소스

MariaDB에서 조회한 현재 시간으로 로그스태시 데이터 수집 시간 (timestamp) 변경한 소스이다.

logstash @timestamp 타임존 기본값은 UTC 0시 = 한국시간 기준 -9시간이라서 필터로 변경해주었다.

input {
    jdbc {
      jdbc_driver_library => "/usr/share/logstash/tools/mariadb-java-client-3.0.7.jar"
      jdbc_driver_class => "Java::org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://DB서버명:포트/DB명"
      jdbc_user => "유저명"
      jdbc_password => "암호"
      statement => "select *, DATE_FORMAT(now(),'%Y-%m-%dT%TZ') now_date from 테이블명" # 현재 시간 ISO8601 형식으로 조회 쿼리
      schedule => "* * * * *" # 쿼리 스케줄링 : 1분에 1번 (cron 표현식. 분0~59 시0~23 일1~31 월1~12 요일0~6)
    }
}

filter {
  date {
    match => ["now_date", "yyyy-MM-dd HH:mm:ss", "ISO8601"] # ISO8601 형식으로 조회한 now_date 필드
    target => "@timestamp" # now_date 필드 값으로 @timestamp 변경
    remove_field => ["now_date"] # now_date 삭제
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "인덱스명" # index는 데이터 수집 시 자동으로 생성됨
    document_id => "%{key컬럼명}" # document의 id로 키 컬럼을 사용하고, 이를 기준으로 insert & update
    #user => "elastic"
    #password => "암호"
  }
}


로그스태시 수집 시 기본 삽입되는 컬럼 삭제

filter {
  date {
    mutate { remove_field => [ "@timestamp", "@version" ] }
  }
}






logstash에서 DB 데이터 수집 시 이용할 MariaDB Connector jar설치


Build.gradle

implementation group: 'org.mariadb.jdbc', name: 'mariadb-java-client', version: '2.7.3'
프로젝트에서 Gradle 빌드 후 얻은 2.7.3 버전 jar로 변경하였음



Gradle 빌드 후 jar 파일 위치

C:\Users\사용자명\.gradle\caches\modules-2\files-2.1\org.mariadb.jdbc\mariadb-java-client\2.7.3\4a2edc05bd882ad19371d2615c2635dccf8d74f0
파일 유형은 Executable Jar File이고, 파일질라로 서버에 올려준다.



/usr/share/logstash/tools 폴더에 바로 올릴 시 에러메세지

open for write: permission denied
해당 폴더의 권한을 변경하거나, /home/유저명 폴더에 올린 후 아래 명령어로 이동시켜준다.

sudo mv /home/유저명/mariadb-java-client-2.7.3.jar /usr/share/logstash/tools


JDBC 드라이버 권한 변경

chmod 661 mariadb-java-client-2.7.3.jar


수정했던 logstash conf 파일 직접 실행
cd /usr/share/logstash
bin/logstash -f /etc/logstash/logstash-sample.conf

실행 시 DB 연결이 안되어 에러메시지 나옴
Unknown setting ' jdbc_connection_string' for jdbc

호스트에서 DB 연결이 가능한지 확인
yum install -y telnet
(윈도우 cmd에서 telnet 명령어 사용하려면
제어판 > 프로그램 추가/제거 > Windows 기능 켜기/끄기 > 텔넷 클라이언트 체크해야 함)

telnet db서버명/db명 포트 해보니 connection refused가 뜨는 것 확인
(윈도우 cmd에서 nslookup 도메인명으로 ip 알아내고 ping 날려보는 방법도 있음.
리눅스에서 nslookup 명령어 사용하려면 yum install -y bind-utils 해야함)

사내 보안상 virtualbox의 새 ip는 DB 접근 권한이 없어서 연결이 불가한 것.
방화벽 적용된 개발서버에서 같은 환경 구성하고 실행 되는지 확인 예정



개발서버(root 아님)에서 같은 환경 구성 후 재실행

cd /usr/share/logstash
sudo bin/logstash -f /etc/logstash/logstash-sample.conf



logstash 실행 시 에러메시지

Path "/usr/share/logstash/data" must be a writable directory.



해결 : /usr/share/logstash 밑 모든 파일 권한을 777로 변경

sudo chmod -R 777 /usr/share/logstash



logstash 실행 시 에러메시지

jdbc_driver_library, file not readable (please check user and group permissions for the path)



해결 : mariadb connector jar 버전 변경

처음에 3.0.7 버전으로 받았다가,

해당 DB 연결하는 프로젝트에서 빌드해서 나온 2.7.3 버전 jar로 변경







logstash로 수집한 elasticsearsh 데이터, kibana에서 조작 방법


1. Discover 화면에서 시각화 테이블로 데이터 확인



메뉴 > Management 클릭 > Data > Index Management

index명 확인 (logstash로 수집 시 index 자동 생성됨)



메뉴 > Management 클릭 > Kibana > Data Views > 우측 Create data view 버튼

Name : index명* 으로 Data Views 생성



메뉴 > Analytics > Discover

좌측 상단에서 index명* Data View 선택

- 데이터 수집 중 Discover 화면 띄우면 각 row의 document(데이터)가 {}로 비어보이는 버그가 있음. 데이터 수집 이후 kibana 페이지를 reload 하면 정상적으로 나옴 (데이터 수집 중 GET api 호출 시에도 정상적으로 나오는 걸 보니 Discover 화면 버그가 맞음)



2. Dev Tools 화면에서 쿼리 날리기

메뉴 > Management > Dev Tools



인덱스 조회 쿼리

GET 인덱스명/_search

단점 : 모든 데이터가 다 나오지는 않음 (~10,000)



인덱스 삭제 쿼리

DELETE 인덱스명







logstash pipeline 설정 (여러 수집 conf 파일 한번에 실행하는 방법)


pipelines.yml 파일 수정

vi /etc/logstash/pipelines.yml



초기 설정 백업 (미사용)

단점 : 

- 첫번째 conf에서 수집한 데이터가 두번째 conf의 index에 insert 되는 버그가 있음

- conf 별로 pipeline 설정을 다르게 줄 수 없음

- pipeline.id: main
  path.config: "/etc/logstash/conf.d/*.conf"


최종 설정 (Good)

두줄 복붙 방법 : readonly 모드로 pipeline.id 줄 위치에서 2yy (복사) 후 원하는 곳에 p (붙여넣기)

- pipeline.id: 인덱스명1
  path.config: "/etc/logstash/conf.d/인덱스명1.conf"
  
- pipeline.id: 인덱스명2
  path.config: "/etc/logstash/conf.d/인덱스명2.conf"
파이프라인 기입 순서는 데이터 수집 순서와 동일하지 않았음



pipeline.id, conf파일명에 conf파일의 output에서 생성할 인덱스명을 포함하여 로그의 구분 편의성을 높이면 좋음



파이프라인별 수집 시간이 동일하면, 같은 시간 병렬 수집이 안되기 때문에 다른 파이프라인은 지연 수집 됨.

각 파이프라인은 시간 텀을 두고 수집하는 것이 서버 부하 분산에도 좋아 30분 간격을 두기로 함.



* conf 파일 수정 후에는 종료 후 재실행 해줘야 수정된 conf 파일을 읽어들여서 데이터가 수정 반영 됨.



conf.d 폴더로 conf 파일들 이동

mv conf파일명.conf /etc/logstash/conf.d


conf 파일 복제

cp conf파일명.conf logstash-db명-테이블명.conf



conf 파일 수정

vi conf파일명.conf



logstash pipeline service 실행

sudo systemctl start logstash



logstash pipeline service 종료

sudo systemctl stop logstash

* kill -9 PID로 종료하면 다시 살아나서 계속 insert 되니 주의







logstash 로그 조회


logstash 로그 실시간 보기

tail -f /var/log/logstash/logstash-plain.log


로그파일 크기 등 정보 보기

ls -lrt
로그 폴더에서 실행하면 로그파일 정보를 볼 수 있다.







로그스태시 서버 분리


운영 엘라스틱서치 서버, 로그스태시 분리 이유

로그스태시 수집 중 문제가 발생하면 엘라스틱서치도 같이 강제 종료되는 경우가 있고, 대량의 데이터 수집 시에는 부하가 발생한다.

위험 부담을 줄이기 위해, 운영 엘라스틱서치 서버에 운영 데이터 수집용 로그스태시를 같이 두지 않기로 했다.

개발 엘라스틱서치 서버의 로그스태시에 개발/운영 데이터 수집용 파이프라인을 별도로 두었다.



개발 데이터 수집용 파이프라인

- pipeline.id: 인덱스명
  path.config: "/etc/logstash/conf.d/인덱스명.conf"

- pipeline.id: 인덱스명2
  path.config: "/etc/logstash/conf.d/인덱스명2.conf"
pipelines_dev.yml 파일로 백업해두고, 개발 데이터 수집이 필요할 때 아래 명령어로 복사한 뒤 로그스태시 실행하였다.

cp pipelines_dev.yml pipelines.yml
