---
title: "Logstash로 MariaDB 데이터 수집 후 엘라스틱서치 저장 방법 / 로그스태시 사용법"
excerpt: ""

categories:
  - 엘라스틱서치
tags:
  - []

permalink: /elk/2022-08-06-1

toc: true
toc_sticky: true

date: 2022-08-06
last_modified_at: 2022-08-06
---

## 엘라스틱서치 매핑 종류

### 동적 매핑
logstash로 데이터 수집 시 인덱스가 없다면 기본 매핑으로 엘라스틱서치에서 인덱스를 자동 생성해주는 것입니다.
- `숫자` : long 타입
- `날짜` : date 타입
- `문자열` : text 타입 + keyword 타입 (멀티 필드)

### 명시적 매핑
개발자가 미리 인덱스 매핑정보를 정의해두는 것입니다.  
인덱스 규모가 커질수록 동적 매핑보다 명시적 매핑이 성능 향상에 좋습니다.

---

## Logstash 설정

### Logstash 수집파일 수정
```
vi /etc/logstash/logstash-테이블명.conf
```
conf 파일 수정 후에는 로그스태시를 종료 후 재실행 해줘야 반영이 됩니다.

### MariaDB 수집 설정
```
input {
    jdbc {
      jdbc_driver_library => "/usr/share/logstash/tools/mariadb-java-client-3.0.7.jar"
      jdbc_driver_class => "Java::org.mariadb.jdbc.Driver"
      jdbc_connection_string => "jdbc:mariadb://DB서버명:포트/DB명"
      jdbc_user => "유저명"
      jdbc_password => "암호"
      statement => "select *, DATE_FORMAT(now(),'%Y-%m-%dT%TZ') now_date from 테이블명" # 현재 시간 ISO8601 형식으로 조회 쿼리
      schedule => "* * * * *" # 쿼리 스케줄링 : 1분에 1번 (cron 표현식. 분0~59 시0~23 일1~31 월1~12 요일0~6)
    }
}

filter {
  date {
    match => ["now_date", "yyyy-MM-dd HH:mm:ss", "ISO8601"] # ISO8601 형식으로 조회한 now_date 필드
    target => "@timestamp" # now_date 필드 값으로 @timestamp 변경
    remove_field => ["now_date"] # now_date 삭제
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "인덱스명" # index는 데이터 수집 시 자동으로 생성됩니다.
    document_id => "%{key컬럼명}" # document의 id로 키 컬럼을 사용하고, 이를 기준으로 insert & update
    #user => "elastic"
    #password => "암호"
  }
}
```
MariaDB에서 조회한 현재 시간으로 로그스태시 데이터 수집 시간 (timestamp) 을 변경한 소스입니다.  
logstash @timestamp 타임존 기본값은 UTC 0시 = 한국시간 기준 -9시간이라서 필터로 변경해주었습니다.

<mark>timestamp 수집 제외 필터</mark>
```
filter {
  date {
    mutate { remove_field => [ "@timestamp", "@version" ] }
  }
}
```
로그스태시 수집 시 기본 삽입되는 timestamp 필드를 삭제할 수 있습니다.

---

## JDBC 드라이버 설치

logstash에서 DB 데이터 수집 시 DB에 연결하기 위한 MariaDB Connector jar를 설치합니다.

### MariaDB Connector jar 생성
```
implementation group: 'org.mariadb.jdbc', name: 'mariadb-java-client', version: '2.7.3'
```
DB 연결이 가능한 SpringBoot에서 Build.gradle에 추가하고 Gradle 빌드 후 2.7.3 버전 jar를 얻습니다.

<mark>Gradle 빌드 후 jar 파일 위치</mark>
```
C:\Users\사용자명\.gradle\caches\modules-2\files-2.1\org.mariadb.jdbc\mariadb-java-client\2.7.3\4a2edc05bd882ad19371d2615c2635dccf8d74f0
```
파일 유형은 Executable Jar File이고, 파일질라로 로그스태시가 설치된 서버에 올려주면 됩니다.

<mark>업로드 시 에러메세지</mark>
```
open for write: permission denied
```
/usr/share/logstash/tools 폴더의 권한을 변경하거나,  
/home/유저명 폴더에 올린 후 아래 명령어로 이동시켜주면 됩니다.
```
sudo mv /home/유저명/mariadb-java-client-2.7.3.jar /usr/share/logstash/tools
```

### JDBC 드라이버 권한 변경
```
chmod 661 mariadb-java-client-2.7.3.jar
```

---

## Logstash 수집파일 실행
```
cd /usr/share/logstash
sudo bin/logstash -f /etc/logstash/logstash-테이블명.conf
```

<mark>Logstash 실행 시 권한 에러</mark>
```
Path "/usr/share/logstash/data" must be a writable directory.
```
아래의 명령어를 실행하여 logstash 폴더 하위 모든 파일 권한을 777로 변경하면 됩니다.
```
sudo chmod -R 777 /usr/share/logstash
```

---

## 키바나에서 수집한 데이터 확인

### Discover 화면에서 테이블로 확인

<mark>1. Management 메뉴 > Data > Index Management</mark>  
logstash로 수집 시 자동 생성된 index명을 확인합니다.

<mark>2. Management 메뉴 > Kibana > Data Views > 우측 Create data view 버튼</mark>  
Name : index명* 으로 Data Views를 생성합니다.

<mark>3. Analytics 메뉴 > Discover</mark>  
좌측 상단에서 index명* Data View를 선택하면 하단에 document 테이블이 조회됩니다.

데이터 수집 중 Discover 화면 띄우면 각 row의 document가 {}로 비어보이는 버그가 있습니다.  
데이터 수집 완료 후 kibana 페이지를 reload 하면 정상적으로 나옵니다.

### Dev Tools 화면에서 쿼리로 확인
<mark>Management 메뉴 > Dev Tools</mark>  
인덱스 검색 쿼리를 실행하여 document를 확인할 수 있습니다.

---

## Logstash pipeline 설정

여러 로그스태시 수집 conf 파일을 한번에 실행하는 파이프라인을 설정하는 방법입니다.

### pipelines.yml 파일 수정
```
vi /etc/logstash/pipelines.yml
```
readonly 모드로 pipeline.id 줄 위치에서 2yy (2줄 복사) 후 원하는 곳에 p (붙여넣기) 하면 편합니다.
```
- pipeline.id: 인덱스명1
  path.config: "/etc/logstash/conf.d/인덱스명1.conf"
  
- pipeline.id: 인덱스명2
  path.config: "/etc/logstash/conf.d/인덱스명2.conf"
  ```
파이프라인에 작성한 순서는 데이터 수집 순서와 일치하지 않습니다.

pipeline.id와 conf파일명에 생성할 인덱스명을 포함하여 로그의 구분 편의성을 높이면 좋습니다.

파이프라인별 수집 시간이 동일하면, 같은 시간 병렬 수집이 안되기 때문에 다른 파이프라인은 지연 수집 됩니다.  
또한, 서버 부하 분산을 위해 각 파이프라인은 30분 간격을 두고 수집하는 것이 좋습니다.

---

## 로그스태시 사용법

### 로그스태시 실행 방법
```
sudo systemctl start logstash
```
파이프라인은 로그스태시 실행 시 자동으로 동작하게 됩니다.

### 로그스태시 종료 방법
```
sudo systemctl stop logstash
```
kill -9 PID로 종료하면 로그스태시 프로세스가 다시 살아나서 계속 수집될 수 있습니다.

### 로그스태시 로그 실시간 조회 방법
```
tail -f /var/log/logstash/logstash-plain.log
```

### 로그파일 크기 확인
```
ls -lrt
```
로그 폴더에서 실행하면 로그파일 정보를 볼 수 있습니다.

---

## 로그스태시 서버 분리 이유

로그스태시 수집 중 문제가 발생하면 엘라스틱서치도 같이 강제 종료되는 경우가 있고,  
대량의 데이터 수집 시에는 부하가 발생하기 때문에 위험 부담을 줄이기 위해서  
운영 엘라스틱서치 서버에 운영 데이터 수집용 로그스태시를 설치하지 않기로 했습니다.

개발 엘라스틱서치 서버의 로그스태시에 개발/운영 데이터 수집용 파이프라인을 각각 두었습니다.

`개발 데이터 수집용 파이프라인` : pipelines_dev.yml  
`운영 데이터 수집용 파이프라인` : pipelines_op.yml

### 파이프라인 변경 예시
```
cp pipelines_dev.yml pipelines.yml
```
위 명령어로 복사한 뒤 로그스태시 실행하면 개발 데이터 수집이 시작됩니다.
