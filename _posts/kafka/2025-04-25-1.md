---
title: "카프카 (apache kafka) 기초 개념 / 카프카 관련 용어 정리"
excerpt: ""

categories:
  - kafka
tags:
  - []

permalink: /kafka/2025-04-25-1

toc: true
toc_sticky: true

date: 2025-04-25
last_modified_at: 2025-04-25
---

카프카 프로젝트 분석을 위해서 학습한 내용을 정리한 글입니다.

---

## 카프카 개념

### 카프카란?
카프카는 중앙 메시지 허브처럼 동작하는 분산 이벤트 스트리밍 플랫폼입니다.  
실시간 데이터 파이프라인, 스트리밍 애플리케이션 구축에 적합합니다.

여러 애플리케이션이 카프카를 통해 메시지 발행(Publish) 하고, 구독(Subscribe) 할 수 있습니다.

링크드인에 데이터를 생성하는 소스 애플리케이션과 데이터를 적재하는 타겟 애플리케이션이 늘어나면서  
아키텍처가 복잡해짐에 따라 데이터 파이프라인의 복잡도를 줄이기 위해 개발된 오픈소스입니다.  
현재는 Apache 재단에서 관리하는 오픈소스이므로 아파치 카프카라고 불립니다.

### 카프카 장점
- 데이터를 배치로 묶어서 주고 받기 때문에, 네트워크 통신 횟수를 줄이고 많은 양의 데이터 전송 가능
- 데이터 요청 수가 가변적인 환경에서 안정적으로 확장 가능 (클러스터 내 브로커 수를 늘려서 스케일아웃)
- 전송받은 데이터를 메모리가 아닌 파일 디스크에 로그 세그먼트 단위로 저장해서 재시작 시 데이터가 보존되는 영속성
- 프로듀서가 보낸 데이터를 각 브로커에 파티션을 복제 저장하여 브로커 장애 시에도 지속적 데이터 처리 가능 (고가용성)
- 데이터 로그 시간을 기반으로 Kafka Streams, ksqlDB 등을 이용해 구체화 뷰 (Materialized View) 를 생성해서 배치 데이터 처리 가능
- 스트리밍 데이터를 저장하고 처리하는 플랫폼 역할 가능
- 프로듀서 전송량이 많아지면 파티션, 컨슈머 수를 늘려서 병렬 처리량 높이고 컨슈머 렉 (지연) 완화 가능
- 프로듀서, 컨슈머 애플리케이션을 개발할 수 있는 Java 기반 공식 클라이언트 라이브러리 제공

---

## 카프카 용어 정리

### 카프카 주요 용어
<table class="table_2_left">
  <tbody>
    <tr>
      <td>클러스터</td>
      <td>카프카 시스템 (카프카 브로커 서버 집합)</td>
    </tr>
    <tr>
      <td>브로커</td>
      <td>
        클러스터 내 프로듀서에서 데이터를 받아서 복제 저장하고, 컨슈머로 데이터를 보내는 서버<br>
        클러스터당 브로커 3~10대 운영이 일반적<br>
        데이터량이 많은 경우 50~100대도 가능
      </td>
    </tr>
    <tr>
      <td>프로듀서</td>
      <td>브로커에 데이터 보내는 역할</td>
    </tr>
    <tr>
      <td>컨슈머</td>
      <td>
        브로커에서 토픽 데이터 가져가는 역할<br>
        데이터는 가져가도 삭제되지 않음<br>
        컨슈머는 여러 개의 파티션 처리 가능<br><br>
        컨슈머 그룹 : 동일한 역할을 하는 컨슈머 묶음
      </td>
    </tr>
    <tr>
      <td>컨슈머 그룹</td>
      <td>동일한 역할을 하는 컨슈머 묶음</td>
    </tr>
    <tr>
      <td>토픽</td>
      <td>
      데이터 구분 단위 (RDBMS의 테이블 개념)<br>
        토픽명은 영어, 숫자, 하이픈 사용 권장<br>
        토픽 이름 변경 불가
      </td>
    </tr>
    <tr>
      <td>파티션</td>
      <td>
        토픽 내에서 데이터가 저장 및 복제되는 단위<br>
        1~1000개 자유롭게 생성 가능<br>
        같은 컨슈머 그룹 내에서는 파티션당 최대 1개의 컨슈머만 처리 가능<br>
        파티션 수를 늘려서 데이터 처리량 늘리기 가능<br>
        생성된 파티션 수를 줄이는 것은 불가하므로 신중하게 늘려야 함
      </td>
    </tr>
    <tr>
      <td>세그먼트</td>
      <td>
        파티션을 저장하는 로그 파일 단위<br>
        토픽 데이터 삭제는 로그 세그먼트 단위로 브로커만 가능
        </td>
    </tr>
    <tr>
      <td>메시지(레코드)</td>
      <td>
        카프카에서 주고 받는 데이터 단위<br>
        오프셋, 타임스탬프, 헤더, 메시지 키, 메시지 값(JSON, 문자열, 바이너리 등) 로 이루어짐<br>
        카프카 메시지는 수정 불가<br>
        같은 메시지 키를 가진 레코드는 동일 파티션에 저장되어 순서가 보장됨
      </td>
    </tr>
    <tr>
      <td>오프셋</td>
      <td>
        브로커가 부여하는 파티션 별 메시지 순번<br>
        처리 완료 데이터, 앞으로 처리할 데이터 구분 용도로 중복 처리 방지
      </td>
    </tr>
  </tbody>
</table>

### 기타 카프카 용어
<table class="table_2_left">
  <tbody>
    <tr>
      <td>주키퍼</td>
      <td>
        카프카 3.0 버전 이하 클러스터 실행을 위해 반드시 필요한 애플리케이션<br>
        과반수 기반으로 동작하여, 최소 3대 이상 실행 필요
      </td>
    </tr>
    <tr>
      <td>컨트롤러</td>
      <td>다른 브로커 상태를 체크하고, 클러스터에서 빠질 장애 브로커 리더 파티션을 재분배하는 역할의 브로커</td>
    </tr>
    <tr>
      <td>커넥트(소스)</td>
      <td>
        DB, S3 등에서 데이터를 가져와서 토픽에 넣는 프로듀서 역할 플러그인<br>
        반복적인 데이터 수집 파이프라인 구축 및 운영 시 사용 추천<br>
        단일성 데이터 수집 파이프라인 구축 시에는 카프카 프로듀서 사용 권장
      </td>
    </tr>
    <tr>
      <td>커넥트(싱크)</td>
      <td>
        토픽 데이터를 JDBC, Elasticsearch 등으로 보내는 컨슈머 역할 플러그인<br>
        반복적인 데이터 전송 파이프라인 구축 및 운영 시 사용 추천<br>
        단일성 데이터 전송 파이프라인 구축 시에는 카프카 컨슈머 사용 권장<br>
        오픈소스 커넥터를 활용하거나, 커스텀 커넥터를 개발하여 배포 및 운영도 가능
      </td>
    </tr>
    <tr>
      <td>커넥터</td>
      <td>
        커넥트에서 운영하는 데이터 파이프라인 관리 단위<br>
        커넥터 설정 및 태스크 관리 담당<br>
        실제 데이터 처리는 여러 태스크가 병렬로 수행
      </td>
    </tr>
    <tr>
      <td>오프셋 커밋</td>
      <td>
        컨슈머가 몇 번 오프셋 메시지까지 처리했는지 기록하는 것<br>
        커밋 시 __consumer_offsets 토픽에 자동 저장됨<br>
        자동 커밋, 수동 커밋 (동기, 비동기 방식) 가능<br>
        레코드 단위 커밋 수행 시 컨슈머 처리 속도 지연 및 브로커 부하<br>
        데이터 처리 후 커밋이 누락되면, 장애 복구 후 데이터 중복 처리 발생
      </td>
    </tr>
    <tr>
      <td>스트림즈(Streams)</td>
      <td>
        토픽에 있는 데이터를 실시간으로 가져와서 처리 후 다시 토픽에 저장할 수 있는 애플리케이션 라이브러리<br>
        스트림 조인, 스트림 테이블 조인 시 조인 기준이 되는 메시지 키 필요
      </td>
    </tr>
    <tr>
      <td>코파티셔닝(co-partitioning)</td>
      <td>
        조인하려는 두 토픽의 파티션 수, 메시지 키 파티셔닝 전략을 동일하게 맞추는 작업<br>
        각 토픽의 같은 메시지 키는 같은 파티션 스트림즈 애플리케이션 태스크에 도달하기 위함<br>
        KStream, KTable은 각 파티션이 각 태스크에 할당되므로 조인 시 코파티셔닝 되어 있어야 함<br>
        GlobalKTable은 각 태스크에서 전체 파티션 데이터를 전역 저장하므로 코파티셔닝 되지 않은 데이터 조인 가능<br>
        GlobalKTable 데이터가 많을 경우 스트림즈 애플리케이션에 부담이 갈 수 있음
      </td>
    </tr>
    <tr>
      <td>리파티셔닝(re-partitioning)</td>
      <td>
        조인하려는 두 토픽의 파티션 수나 키 분포가 다를 때,<br>
        Kafka Streams가 메시지 키 기준으로 데이터를 재분배하여<br>
        조인 조건에 맞는 내부 토픽을 자동 생성하는 작업<br><br>
        단점 : 디스크 공간 사용량 증가
      </td>
    </tr>
    <tr>
      <td>리밸런싱</td>
      <td>
        파티션 수 또는 컨슈머 그룹 내 컨슈머 수 변화로 인해 파티션 할당이 변경되는 과정<br>
        장애 컨슈머가 컨슈머 그룹에서 빠지면 파티션 해제 후 다른 컨슈머로 재할당
      </td>
    </tr>
    <tr>
      <td>레플리케이션(Replication)</td>
      <td>리더 파티션 데이터가 다른 브로커의 팔로워 파티션에 복제되는 과정</td>
    </tr>
    <tr>
      <td>어사이너(Assignor)</td>
      <td>
        파티션을 컨슈머에게 할당하는 역할<br>
        카프카 2.5.0 기본값 : RangeAssignor (토픽의 파티션 정렬 후 각 컨슈머에게 할당)
      </td>
    </tr>
  </tbody>
</table>

### 카프카 파티션 관련 용어
<table class="table_2_left">
  <tbody>
    <tr>
      <td>리더 파티션</td>
      <td>프로듀서, 컨슈머와 통신하는 브로커의 파티션</td>
    </tr>
    <tr>
      <td>팔로워 파티션</td>
      <td>
        리더 파티션을 가진 브로커가 아닌, 다른 브로커들의 복제된 파티션<br>
        데이터 복제용이라 프로듀서, 컨슈머와 직접 통신 불가
      </td>
    </tr>
    <tr>
      <td>ISR (In-Sync-Replicas)</td>
      <td>
        리더 파티션, 팔로워 파티션들이 모두 싱크되어 오프셋 수가 거의 동일한 상태<br>
        동기화 여부를 나타내는 지표<br>
        ISR에 포함된 팔로워만 장애 시 리더로 승격되어 데이터 손실 없이 복구
      </td> 
    </tr>
  </tbody>
</table>

### 프로듀서 관련 용어
<table class="table_2_left">
  <tbody>
    <tr>
      <td>프로듀서 레코드</td>
      <td>프로듀서에서 생성하여 전송하는 레코드 객체 (오프셋 미포함)</td>
    </tr>
    <tr>
      <td>send()</td>
      <td>
        KafkaProducer API의 레코드 비동기 전송 요청 메서드<br>
        파티셔너 → 어큐뮬레이터 → 센더 → 브로커 전송
      </td>
    </tr>
    <tr>
      <td>파티셔너</td>
      <td>
        레코드를 어느 파티션에 전송할지 결정하는 역할<br>
        메시지 키가 있으면 해시 기반으로 파티션 결정<br>
        메시지 값만 있으면 라운드 로빈 방식으로 파티션 할당<br>
        UniformStickyPartitioner는 레코드들이 배치로 묶일 때까지 기다렸다가 전송하므로 RoundRobinPartitioner에 비해 향상된 성능<br>
        커스텀 파티셔너를 사용하면 특정 메시지 키 또는 값을 항상 특정 파티션으로 보낼 수 있음
      </td>
    </tr>
    <tr>
      <td>어큐뮬레이터(Accumulator)</td>
      <td>
        파티셔너에서 전송할 레코드를 받고, 배치로 묶어 모으는 버퍼<br>
        일정 크기나 시간에 도달하면 Sender 스레드가 네트워크로 전송
      </td>
    </tr>
  </tbody>
</table>

### 컨슈머 관련 용어
<table class="table_2_left">
  <tbody>
    <tr>
      <td>Fetcher</td>
      <td>
        리더 파티션으로부터 레코드들을 배치로 미리 가져오는 역할<br>
        내부 버퍼 completedFetches에 저장 후 대기
      </td>
    </tr>
    <tr>
      <td>poll()</td>
      <td>Fetcher에 있는 레코드들을 리턴하는 메서드</td>
    </tr>
    <tr>
      <td>ConsumerRecords</td>
      <td>컨슈머가 처리할 레코드 모음 (오프셋 포함)</td>
    </tr>
  </tbody>
</table>
