---
title: "카프카 스트림즈 개념 정리 / Java 카프카 스트림즈 애플리케이션 개발 방법"
excerpt: ""

categories:
  - Kafka
tags:
  - []

permalink: /kafka/2025-05-12-1

toc: true
toc_sticky: true

date: 2025-05-12
last_modified_at: 2025-05-12
---

## 카프카 스트림즈 개념 정리

카프카 스트림즈를 이용하면 토픽 스트림 데이터 처리 후, 토픽 또는 외부 시스템에 저장할 수 있습니다.

처리할 토픽 파티션이 3개면 스트림즈 애플리케이션 내부에 3개의 태스크가 자동으로 할당됩니다.  
파티션 수만큼 생성된 태스크들이 병렬로 데이터를 처리하므로 성능이 좋습니다.

같은 application.id로 스트림즈 애플리케이션들을 실행하면,  
프로세스-스레드가 분리되어 일부 프로세스에 장애가 발생해도 안정적인 운영이 가능합니다.

<mark>스트림즈 프로세서 종류</mark>
- 소스 프로세서 : 토픽에서 데이터를 가져오는 역할
- 스트림즈 프로세서 : 다른 프로세서가 반환한 데이터를 처리하는 역할
- 싱크 프로세서 : 처리가 완료된 데이터를 다른 토픽에 저장하는 역할

### 스트림즈DSL
스트림즈 애플리케이션 개발 시 주로 사용되는 API입니다.  
메시지 값을 기반으로 토픽 분기, 지난 10분간 들어온 데이터 수 집계 등이 가능합니다.

<mark>KStream</mark>
컨슈머처럼 토픽을 실시간으로 구독하고, 레코드를 순차적으로 하나씩 처리하는 비상태 스트림 처리 모델입니다.

<mark>KTable</mark>
토픽의 메시지 키를 기준으로 가장 최신 레코드만 유지하는 상태 기반 스트림 처리 모델입니다.  
스트림즈 애플리케이션의 각 태스크에 Materialized View (구체화된 뷰) 로 저장됩니다.

<mark>GlobalKTable</mark>
전체 토픽의 모든 파티션 데이터를 복제해 보유하는 전역 상태 기반 스트림 처리 모델입니다.  
스트림즈 애플리케이션의 각 태스크에 Materialized View (구체화된 뷰) 로 저장됩니다.

### 프로세서 API
스트림즈 애플리케이션 개발 시 스트림즈DSL보다 세밀한 로직 구현이 가능한 API입니다.  
스트림즈DSL과 함께 사용하면 KStream, KTable, GlobalKTable 개념과 연동할 수 있습니다.  
메시지 값 종류에 따라 동적으로 토픽 전송, 일정한 시간 간격으로 데이터 처리 등이 가능합니다.

<mark>Processor 인터페이스</mark>
입력 데이터 처리 후 다음 프로세서로 데이터를 자동 전달하지 않고 직접 제어할 때 사용합니다.  
ProcessorContext를 이용하면 필요한 시점에만 데이터를 전달할 수 있습니다.

<mark>Transformer 인터페이스</mark>  
입력 데이터 처리 후 다음 프로세서로 데이터를 전달할 때 사용합니다.

---

## 카프카 스트림즈DSL 애플리케이션 개발

Java 프로젝트 생성 후 아래와 같이 구현하고 Java 프로세스를 실행하면 됩니다.

### 카프카 스트림즈 라이브러리 추가
```
dependencies {
    implementation 'org.apache.kafka:kafka-streams:2.5.0'
    implementation 'org.slf4j:slf4j-simple:1.7.30'
}
```
java 프로젝트 내 build.gradle 파일에 카프카 브로커와 동일한 버전의 스트림즈 라이브러리를 추가합니다.  
카프카 스트림즈 로그 출력을 위해 slf4j 라이브러리 의존성도 추가합니다.

### KStream 필터링 스트림즈 애플리케이션 예시
```
public class StreamsFilter {
  private final static Logger LOGGER = LoggerFactory.getLogger(StreamsFilter.class);
  private final static String BOOTSTRAP_SERVERS = "localhost:9092";
  private final static String APPLICATION_ID = "스트림즈애플리케이션그룹ID";

  public static void main(String[] args) {

    // 스트림즈DSL 필수 옵션 설정
    Properties props = new Properties();
    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
    props.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_ID);
	
	  // 스트림즈DSL 선택 옵션 설정
    props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
    props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

    // 스트림빌더 정의 시작
    StreamsBuilder builder = new StreamsBuilder();

    // 토픽 KStream 생성
    KStream<String, String> streamLog = builder.stream("소스토픽명");

    // 소스 토픽 필터링
    KStream<String, String> filteredStream = streamLog.filter(
      (key, value) -> value != null && value.length() > 5
    );

    // 필터링 결과 싱크 토픽에 저장
    filteredStream.to("싱크토픽명");

    // 카프카 스트림즈 실행
    KafkaStreams streams;
    streams = new KafkaStreams(builder.build(), props);
    streams.start();

    // 카프카 스트림즈 종료 셧다운 훅
    Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
  }
}
```
토픽에 들어온 레코드의 메시지 키 또는 값을 필터링하는 비상태 스트림즈 애플리케이션 예시입니다.  
실시간으로 소스 프로세서에서 받은 소스 토픽 레코드를 스트림 프로세서에서 필터링합니다.  
조건에 맞는 레코드만 싱크 프로세서로 전달하여 싱크 토픽에 저장합니다.

### KStream, KTable 조인 예시
```
// 스트림빌더 정의 시작
StreamsBuilder builder = new StreamsBuilder();

// 소스 프로세서 이용하여 토픽 KStream, KTable 생성
KStream<String, String> orderStream = builder.stream("주문_소스토픽명");
KTable<String, String> addressTable = builder.table("주소_소스토픽명");

// KStream, KTable 조인 후 싱크토픽에 저장
orderStream.join(addressTable, (order, adress) -> order + "send to" + address)
           .to("싱크토픽명");

// 카프카 스트림즈 실행
KafkaStreams streams;
streams = new KafkaStreams(builder.build(), props);
streams.start();
```
주문 소스토픽에 데이터가 들어오면 최신 주소만 유지하는 주소 소스토픽 KTable과 조인하고,  
조인 결과를 싱크 토픽에 저장하는 스트림즈 애플리케이션 예시입니다.  
메시지 키가 동일한 데이터만 실시간으로 조인되며, 메시지 키가 null이면 조인되지 않습니다.

### KStream, GlobalKTable 조인 예시
작성예정

---

## 프로세서 API 사용한 스트림즈 애플리케이션 개발

### Processor 인터페이스 구현 예시
```
public class FilterProcessor implements Processor<String, String> { // 메시지 키, 메시지 값 타입 지정
  private ProcessorContext context;

  @Override
  public void init(ProcessorContext context) {
    // 컨텍스트 초기화
    this.context = context;
  }

  @Override
  public void process(String key, String value) {
    if (value.length() > 5) {
      // 컨텍스트 이용해서 다음 프로세서로 데이터 전달
      context.forward(key, value);
    }

    // 오프셋 커밋 (필요 시 호출)
    context.commit();
  }

  @Override
  public void close() {
    // 리소스 해제 처리
  }
}
```
메시지 처리 흐름을 제어하는 Processor 인터페이스를 구현합니다.  
아래와 같이, 구현한 Processor 클래스를 스트림 Processor 노드로 지정하면 됩니다.
```
// 토폴로지 생성
Topology topology = new Topology();

// 소스 프로세서, 스트림 프로세서, 싱크 프로세서 지정
topology.addSource("Source", 소스토픽명)
        .addProcessor("Process",
                      () -> new FilterProcessor(),
                      "Source")
        .addSink("Sink", 싱크토픽명, "Process");

// 카프카 스트림즈 인스턴스 생성
KafkaStreams streaming = new KafkaStreams(topology, props);

// 스트림즈 애플리케이션 실행
streaming.start();
```
