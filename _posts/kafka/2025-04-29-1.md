---
title: "아파치 카프카 설정 방법 / 카프카 스크립트 종류"
excerpt: ""

categories:
  - 카프카
tags:
  - []

permalink: /kafka/2025-04-29-1

toc: true
toc_sticky: true
 
date: 2025-04-29
last_modified_at: 2025-04-29
---

## 카프카 브로커 설정

### 로그 디렉터리 설정
```
log.dir (작성예정)
```
config/server.properties 파일의 log.dir 옵션에 정의한 디렉터리에 로그를 저장합니다.  
'토픽명-파티션번호' 하위 디렉터리를 자동 생성하여 분류합니다.

<mark>카프카 도커 옵션 예시</mark>
```
KAFKA_LOG_DIRS: '/tmp/kafka-logs'
```

<mark>토픽-파티션별 카프카 로그 파일 예시</mark>
- 00000000000000000000.log : 오프셋, 메시지 키, 메시지 값, 헤더, 타임스탬프 등 실제 메시지 데이터 저장
- 00000000000000000000.index : 오프셋과 로그 파일 내 위치를 매핑한 인덱스 파일
- 00000000000000000000.timeindex : 타임스탬프와 로그 파일 내 위치를 매핑한 인덱스 파일
- leader-epoch-checkpoint : 리더 에폭 정보 저장 (리더 변경 기록 관리)
- partition.metadata : 파티션 설정 정보 저장
파일명이 00000000000000000010.log면, 오프셋 10번부터의 데이터가 저장된 로그 파일입니다.  
프로듀서에서 받은 메시지에 브로커가 오프셋을 부여하고, 타임스탬프를 지정하여 저장합니다.

### 로그 파일 생성주기 설정
```
-- 로그 파일 (=세그먼트 파일) 최대 크기 지정
log.segment.bytes
또는
-- 세그먼트 신규 생성 후 다음 파일로 넘어가는 주기 (기본값 7일)
log.roll.ms(hosurs)
```

### 로그 파일 삭제주기 설정
```
-- 세그먼트 삭제 주기. 리텐션 기간 (기본값 7일, 일반적으로 3일)
retention.ms(minutes, hours)
또는
-- 파티션당 로그 최대 크기 도달 시 삭제 (기본값 -1)
retrntion.bytes

-- 삭제 대상 체크 주기 (기본값 5분)
log.retention.check.interval.ms
```
카프카 데이터는 세그먼트 단위로 삭제되며, 레코드 단위 삭제 및 수정은 불가합니다.

<mark>액티브 세그먼트</mark>
쓰기가 일어나고 있는 가장 마지막 세그먼트 파일을 액티브 세그먼트라고 합니다.  
액티브 세그먼트는 브로커의 삭제 대상이 되지 않습니다.  
일반 세그먼트는 retention 옵션 기간이 지나면 삭제될 수 있습니다.

### 컴팩트 설정
```
cleanup.policy=compact
```
액티브 세그먼트, 각 메시지 키의 가장 최신 레코드 제외 후 오래된 레코드들만 삭제하여 압축합니다.  
- 클린 로그 (테일 영역) : 압축이 완료된 로그 (중복 메시지 키 없음)
- 더티 로그 (헤드 영역) : 압축 정책 실행 전 로그 (중복 메시지 키 있음)

<mark>압축 시작 시점 설정</mark>
```
min.cleanable.dirty.ratio
```
클린 레코드에 비한 더티 레코드 비율에 따라 압축 실행합니다.  
- 0.9 : 압축 효과가 좋으나, 더티 레코드 0.9 비율이 될 때까지 용량 효율이 좋지 않습니다.
- 0.1 : 압축이 자주 일어나서 브로커에 부담이 되고, 최신 데이터만 유지할 수 있습니다.

---

## 카프카 토픽 설정

토픽 단위로 설정할 수 있는 옵션들입니다.

### 파티션 복제 개수 설정
```
replication.factor
```
토픽 생성 시 파티션 복제 개수는 최소 1 (복제 없음) 부터 최대 브로커 개수까지 설정 가능합니다.  
운영 브로커가 5개면, 2~3으로 설정하는 것이 일반적입니다.  
각 파티션을 복제하여 디스크 용량을 차지하는 대신, 시스템 안정성과 가용성을 높일 수 있습니다.

<mark>파티션 복제 개수 설정 시 참고</mark>  
일부 데이터가 유실되어도 되는 GPS 데이터는 복제하지 않고 운영하기도 합니다.  
데이터가 유실되면 안되는 금융 데이터는 복제 개수를 3으로 설정하여 운영하기도 합니다.

### 파티션 리더 승급 설정
```
-- 데이터 유실을 감수하고, 지속적으로 데이터 처리
-- 복제가 안된 (ISR이 아닌) 팔로워 파티션을 리더로 승급하는 옵션
unclean.leader.election.enable=true

-- 데이터 유실을 감수하지 않고, 리더 파티션이 복구될 때까지 중단
-- 복제가 안된 (ISR이 아닌) 팔로워 파티션을 리더로 승급하지 않는 옵션
unclean.leader.election.enable=false
```

### 메시지 타임스탬프 설정
```
message.timestamp.type
```
타임스탬프 기본값은 프로듀서 레코드 생성 시간이고, 브로커 적재 시간으로 변경 가능합니다.

---

## 카프카 프로듀서 설정

### 프로듀서 메타데이터 옵션
```
-- 메타데이터 강제 갱신 요청 주기 (기본값 5분)
metadata.max.age.ms

-- 프로듀서 유휴 상태 시 메타데이터 캐시 유지 주기 (기본값 5분)
metadata.max.idle.ms
```
카프카 프로듀서는 초기 메시지 전송 전 또는 메시지 전송 중 오류가 발생했을 때 클러스터에 메타데이터를 요청하고 응답 받아서 캐시에 저장합니다.  
메타데이터로 각 토픽의 리더 파티션이 어떤 브로커에 있는지 알 수 있습니다.  
정확한 브로커와 메시지를 통신하기 위해 프로듀서, 컨슈머는 메타데이터 갱신이 주기적으로 필요합니다.  
컨슈머에서 잘못된 브로커로 데이터 요청 시에는 LEADER_NOT_AVAILABLE 익셉션이 발생합니다.




---

## 카프카 스크립트

### 카프카 스크립트 종류
<table class="table_2_left">
  <tbody>
    <tr>
      <td>kafka-server-start.sh</td>
      <td>카프카 브로커 실행</td>
    </tr>
    <tr>
      <td>kafka-server-stop.sh</td>
      <td>카프카 브로커 종료</td>
    </tr>
    <tr>
      <td>zookeeper-server-start.sh</td>
      <td>주키퍼 서버 실행</td>
    </tr>
    <tr>
      <td>zookeeper-server-stop.sh</td>
      <td>주키퍼 서버 종료</td>
    </tr>
    <tr>
      <td>kafka-topics.sh</td>
      <td>토픽 생성, 삭제, 조회, 설정 변경 등 관리</td>
    </tr>
    <tr>
      <td>kafka-console-producer.sh</td>
      <td>터미널에서 메시지를 입력하고 전송하는 프로듀서 실행</td>
    </tr>
    <tr>
      <td>kafka-console-consumer.sh</td>
      <td>터미널에서 메시지를 실시간으로 읽는 컨슈머 실행</td>
    </tr>
    <tr>
      <td>kafka-consumer-groups.sh</td>
      <td>컨슈머 그룹 상태 조회, 오프셋 이동 등</td>
    </tr>
    <tr>
      <td>kafka-configs.sh</td>
      <td>사용자/브로커/토픽 등 설정값 변경</td>
    </tr>
    <tr>
      <td>kafka-acls.sh</td>
      <td>ACL 설정 (접근 제어)</td>
    </tr>
    <tr>
      <td>kafka-reassign-partitions.sh</td>
      <td>파티션 재할당 작업<br>
      <br>특정 브로커에 리터 파티션이 몰리는 경우 사용하면 좋은 명령어입니다.
      <br>리더 파티션을 각 브로커에 균등하게 재분배하여 네트워크 통신으로 인한 리소스 부하를 분산합니다.
      </td>
    </tr>
    <tr>
      <td>kafka-preferred-replica-election.sh</td>
      <td>선호 리더 선출 실행</td>
    </tr>
    <tr>
      <td>kafka-run-class.sh</td>
      <td>임의의 Kafka 클래스 실행 (고급용)</td>
    </tr>
    <tr>
      <td>kafka-verifiable-consumer.sh</td>
      <td>테스트용 컨슈머 (정합성 테스트)</td>
    </tr>
    <tr>
      <td>kafka-verifiable-producer.sh</td>
      <td>테스트용 프로듀서 (정합성 테스트)</td>
    </tr>
    <tr>
      <td>connect-standalone.sh</td>
      <td>커넥트 단일 모드 실행</td>
    </tr>
    <tr>
      <td>connect-distributed.sh</td>
      <td>커넥트 클러스터 모드 실행</td>
    </tr>
    <tr>
      <td>kafka-producer-perf-test.sh</td>
      <td>프로듀서 성능 테스트</td>
    </tr>
    <tr>
      <td>kafka-consumer-perf-test.sh</td>
      <td>컨슈머 성능 테스트</td>
    </tr>
    <tr>
      <td>kafka-storage.sh</td>
      <td>로그 디렉터리 포맷 및 검증</td>
    </tr>
    <tr>
      <td>kafka-metadata-shell.sh</td>
      <td>메타데이터 수동 조회 (고급 기능)</td>
    </tr>
  </tbody>
</table>
