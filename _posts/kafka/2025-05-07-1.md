---
title: "IntelliJ 카프카 프로듀서, 컨슈머 애플리케이션 개발 방법"
excerpt: ""

categories:
  - Kafka
tags:
  - []

permalink: /kafka/2025-05-07-1

toc: true
toc_sticky: true

date: 2025-05-07
last_modified_at: 2025-05-07
---

## Java 프로젝트 생성

카프카 프로듀서, 컨슈머 애플리케이션은 Java 프로젝트로 개발할 수 있습니다.  
Javascript, go, Python 등으로도 가능하지만, 공식 지원되는 라이브러리 언어는 Java입니다.

### IntelliJ Java 프로젝트 생성 방법
File > New > Project... > 아래와 같이 입력 후 Create
<table>
  <tbody>
    <tr>
      <td>Name</td>
      <td>프로젝트명 입력</td>
    </tr>
    <tr>
      <td>Language</td>
      <td>Java 1.8 이상 선택</td>
    </tr>
    <tr>
      <td>Build system</td>
      <td>Gradle 선택</td>
    </tr>
    <tr>
      <td>JDK</td>
      <td>18 이상 선택</td>
    </tr>
    <tr>
      <td>Gradle DSL</td>
      <td>Groovy 선택</td>
    </tr>
  </tbody>
</table>
프로젝트가 생성되면 src/main/java 폴더 안에 패키지 폴더를 만들어야 합니다.  
패키지 폴더 내에 프로듀서 애플리케이션, 컨슈머 애플리케이션 클래스를 작성하면 됩니다.

### 카프카 클라이언트 라이브러리 추가
```
dependencies {
    implementation 'org.apache.kafka:kafka-clients:2.5.0'
    implementation 'org.slf4j:slf4j-simple:1.7.30'
}
```
java 프로젝트 내 build.gradle 파일에 카프카 브로커와 동일한 버전의 클라이언트 라이브러리를 추가합니다.  
카프카 클라이언트 로그 출력을 위해서 slf4j 라이브러리 의존성도 추가합니다.

---

## 카프카 프로듀서 애플리케이션 개발

### 프로듀서 클래스 예시
```
public class TestProducer {
  private final static Logger LOGGER = LoggerFactory.getLogger(TestProducer.class);
  private final static String TOPIC_NAME = "토픽명";
  private final static String BOOTSTRAP_SERVERS = "localhost:9092";

  public static void main(String[] args) {

    // 프로듀서 필수 옵션 설정
    Properties configs = new Properties();
    configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS); // 요청할 브로커 서버 정의
    configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 메시지 키 직렬화 클래스 정의
    configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // 메시지 값 직렬화 클래스 정의

    // 프로듀서 생성
    KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

    // 메시지 값 프로듀서 레코드 생성
    ProducerRecord<String, String> record1 = new ProducerRecord<>(TOPIC_NAME, "메시지 값");

    // 메시지 키-값 프로듀서 레코드 생성
    ProducerRecord<String, String> record2 = new ProducerRecord<>(TOPIC_NAME, "메시지 키", "메시지 값");

    // 파티션 번호를 지정한 프로듀서 레코드 생성
    ProducerRecord<String, String> record3 = new ProducerRecord<>(TOPIC_NAME, 0, "메시지 키", "메시지 값");

    try {
      // 메시지 비동기 전송 (파티셔너 → Accumulator → 브로커 → 파티션에 로그 세그먼트 파일 저장)
      // Accumulator에서 배치로 묶이면 일정 크기 및 시간에 도달 시 전송
      producer.send(record1);
      producer.send(record2);

      // 메시지 동기 전송
      RecordMetadata metadata = producer.send(record3).get();

      // 콜백 출력 결과 : 토픽명-파티션번호@오프셋번호
      // 오프셋번호가 -1이면, acks 옵션이 0이라 응답이 없는 것
      LOGGER.info(metadata.toString());

    } catch (Exception e) {
      LOGGER.error(e.getMessage(), e);

    } finally {
      // accumulator에 전송 대기 중인 메시지 전송
      producer.flush();
      
      // 프로듀서 종료 (리소스 해제)
      producer.close();
    }
  }
}
```
Java 라이브러리로 카프카 프로듀서를 생성하고, 브로커로 메시지를 보내는 예시입니다.

### 프로듀서 옵션 설정
<mark>프로듀서 필수 옵션</mark>
<table class="table_2_left">
  <tbody>
    <tr>
      <td>bootstrap.servers</td>
      <td>
        프로듀서가 레코드를 전송할 카프카 클러스터 내 브로커 호스트명:포트 목록 작성<br>
        2개 이상 작성 시 브로커 장애 대비 가능
      </td>
    </tr>
    <tr>
      <td>key.serializer</td>
      <td>
        메시지 키를 직렬화 할 클래스 지정<br>
        String Serializer로 통일하면 컨슈머 역직렬화 클래스 설정 및 디버깅 시 용이
      </td>
    </tr>
    <tr>
      <td>value.serializer</td>
      <td>메시지 값을 직렬화 할 클래스 지정</td>
    </tr>
  </tbody>
</table>

<mark>프로듀서 선택 옵션</mark>
<table class="table_2_left">
  <tbody>
    <tr>
      <td>acks ★</td>
      <td>
        프로듀서가 보낸 데이터에 대해 브로커로부터 성공 응답을 받을 조건 설정<br>
        복제 강도를 높여서 성능 낮추고 신뢰성 높게 저장할지 여부<br>
        복제 개수가 많을수록 차이가 큼<br>
        기본값 : 1<br><br>
        0 : 데이터 전송 후 응답 확인 X (가장 빠르지만 브로커 장애 시 데이터 유실 위험 큼)<br>
        1 : 리더 브로커에 레코드 저장 시 성공 응답<br>
        all 또는 -1: 리더 + ISR에 포함된 팔로워들에 레코드 저장 시 성공 응답 (가장 느리고 신뢰성 높음)
      </td>
    </tr>
    <tr>
      <td>linger.ms</td>
      <td>
        Accumulator에 모은 배치 데이터 전송 전 기다리는 최소 시간<br>
        기본값 : 0 (Send 시 즉시 전송)
      </td>
    </tr>
    <tr>
      <td>retries</td>
      <td>
        브로커 전송 실패 시 재전송 시도 횟수<br>
        기본값 : Integer.MAX_VALUE (2147483647)
      </td>
    </tr>
    <tr>
      <td>max.in.flight.requests.per.connection</td>
      <td>
        한 커넥션에서 동시 전송할 수 있는 최대 요청 수<br>
        기본값 : 5 (순서 보장 필요 시 1로 설정)
      </td>
    </tr>
    <tr>
      <td>partitioner.class</td>
      <td>
        레코드를 어느 파티션에 보낼지 결정하는 파티셔너 클래스 지정<br>
        기본값 : DefaultPartitioner (카프카 2.4 이상 : UniformStickyPartitioner)
      </td>
    </tr>
    <tr>
      <td>enable.idempotence</td>
      <td>
        네트워크 오류, 재시도 상황에서도 중복 없이 한 번만 레코드를 전송하는 멱등성 보장 여부<br>
        기본값 : true (중복 전송 방지로 안정성 향상)
      </td>
    </tr>
    <tr>
      <td>transactional.id</td>
      <td>
        레코드를 트랙잭션 단위로 묶어서 전송 여부<br>
        기본값 : null (트랜잭션 프로듀서가 아닌, 기본 프로듀서로 동작)
      </td>
    </tr>
  </tbody>
</table>
카프카 2.5.0 버전 기준 기본값이며, 사용하는 클라이언트 라이브러리 버전에 따라 기본값이 다를 수 있습니다.

---

## 카프카 컨슈머 애플리케이션 개발

### 자동 커밋 컨슈머 클래스 예시
```
public class TestConsumer {
  private final static Logger LOGGER = LoggerFactory.getLogger(TestConsumer.class);
  private final static String TOPIC_NAME = "토픽명";
  private final static String BOOTSTRAP_SERVERS = "localhost:9092";
  private final static String GROUP_ID = "컨슈머그룹ID";
  private static KafkaConsumer<String, String> consumer;

  public static void main(String[] args) {

    // 컨슈머 필수 옵션 설정
    Properties configs = new Properties();
    configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
    configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);
    configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

    // 컨슈머 선택 옵션 설정
    configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true); // 기본값 : true 이므로, 명시하지 않아도 자동 커밋 됨
    configs.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 60000); // 자동 커밋 주기 : 1분 (이후 poll 호출 시 자동 커밋)

    // 컨슈머 생성
    consumer = new KafkaConsumer<>(configs);

    // 런타임 종료 시 실행되는 스레드 셧다운 훅 등록
    Runtime.getRuntime().addShutdownHook(new ShutdownThread());

    // 토픽 구독
    consumer.subscribe(Arrays.asList(TOPIC_NAME));

    try {

      // 무한루프
      while (true) {
        // 최대 1초 대기하며 메시지 요청
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

        // 받은 메시지가 있으면 출력
        for (ConsumerRecord<String, String> record : records) {
          LOGGER.info("record:{}", record);
        }
      }

    } catch (WakeupException e) {
      LOGGER.error(e.getMessage(), e);

    } finally {
      // 컨슈머 종료 (컨슈머 그룹에서 제외)
      consumer.close();
    }
  }

  // 런타임 종료 시 실행되는 스레드 클래스 구현
  static class ShutdownThread extends Thread {
    public void run() {
      // 컨슈머 poll 진행 중단 (WakeupException 발생)
      // 런타임 스레드가 아닌 다른 스레드에서 호출해야 안전하게 종료 가능
      consumer.wakeup();
    }
  }
}
```
컨슈머 그룹이 토픽을 구독하고 전체 파티션에 대해서 메시지를 가져가는 예시입니다.  
토픽의 파티션 수 : 컨슈머 그룹 내 컨슈머 수는 1:1로 운영하는 것이 좋습니다.  
파티션은 1개의 컨슈머만 할당 가능하므로, 파티션 수보다 많은 컨슈머는 유휴 상태가 됩니다.

### 수동 커밋 컨슈머 예시

<mark>자동 커밋 비활성화 옵션 설정</mark>
```
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
```
수동 커밋은 컨슈머 생성 시 파라미터 configs에 자동 커밋 비활성화 옵션을 넣어야 합니다.

<mark>동기 오프셋 커밋 예시</mark>
```
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

  for (ConsumerRecord<String, String> record : records) {
    LOGGER.info("record:{}", record);
  }

  // 동기 오프셋 커밋
  consumer.commitSync();
}
```
커밋 응답을 기다리는 동기 오프셋 커밋 예시입니다.  
레코드 처리가 끝난 후 커밋해야 합니다.

<mark>레코드 단위 동기 오프셋 커밋 예시</mark>
```
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

  // 파티션별 현재 오프셋 데이터 맵 생성
  Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>();

  for (ConsumerRecord<String, String> record : records) {
    LOGGER.info("record:{}", record);

    // 파티션별 현재 오프셋 데이터 맵 갱신
    currentOffset.put(
      new TopicPartition(record.topic(), record.partition()),
      new OffsetAndMetadata(record.offset() + 1, null)
    );

    // 레코드 단위 동기 오프셋 커밋
    // 이미 커밋된 파티션-오프셋은 무시
    consumer.commitSync(currentOffset);
  }
}
```
레코드 단위 커밋은 비효율적이고, 데이터가 많을수록 느려져서 잘 사용되지 않는 방식입니다.

<mark>비동기 오프셋 커밋 예시</mark>
```
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

  for (ConsumerRecord<String, String> record : records) {
    LOGGER.info("record:{}", record);
  }

  // 비동기 오프셋 커밋
  consumer.commitAsync();
}
```
비동기 오프셋은 커밋 수행 시 응답을 기다리지 않으므로, 더 많은 데이터를 처리할 수 있습니다.

<mark>비동기 오프셋 커밋 콜백 예시</mark>
```
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

  for (ConsumerRecord<String, String> record : records) {
    LOGGER.info("record:{}", record);
  }

  // 비동기 오프셋 커밋 후 완료 콜백 함수 실행
  consumer.commitAsync(new OffsetCommitCallback() {
    @Override
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception e) {
      if (e != null) {
        // 커밋 실패
        e.printStackTrace();
      } else {
        // 커밋 성공
        LOGGER.info("커밋 성공 오프셋:{}", offsets);
      }
    }
  });
}
```

### 파티션 수동 할당 컨슈머 예시
```
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);

// 리밸런싱을 위한 컨슈머 그룹을 사용하지 않고, 컨슈머에 토픽 파티션 직접 할당
consumer.assign((Collections.singleton(new TopicPartition(TOPIC_NAME, PARTITION_NUMBER))));

while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

  for (ConsumerRecord<String, String> record : records) {
    LOGGER.info("record:{}", record);
  }
}
```
subscribe를 사용하지 않아서 GroupID 옵션 지정이 필수가 아닙니다.

### 컨슈머 옵션 설정
<mark>컨슈머 필수 옵션</mark>
<table class="table_2_left">
  <tbody>
    <tr>
      <td>bootstrap.servers</td>
      <td>
        컨슈머가 카프카 클러스터에 연결할 때 사용할 브로커 호스트명:포트 목록 작성<br>
        2개 이상 작성 시 브로커 장애 대비 가능
      </td>
    </tr>
    <tr>
      <td>key.deserializer</td>
      <td>
        토픽에서 읽은 메시지 키를 역직렬화 할 클래스 지정<br>
        프로듀서에서 직렬화 한 클래스와 동일하게 설정
      </td>
    </tr>
    <tr>
      <td>value.deserializer</td>
      <td>토픽에서 읽은 메시지 값을 역직렬화 할 클래스 지정</td>
    </tr>
  </tbody>
</table>

<mark>컨슈머 선택 옵션</mark>
<table class="table_2_left">
  <tbody>
    <tr>
      <td>group.id</td>
      <td>컨슈머가 속할 컨슈머 그룹 ID<br>subscribe()로 토픽 구독 시 필수 값</td>
    </tr>
    <tr>
      <td>auto.offset.reset ★</td>
      <td>
        파티션 읽을 때 컨슈머 오프셋이 없는 경우, 어느 오프셋부터 읽을지 설정<br>
        기본값 : latest<br><br>latest : 가장 최근 오프셋부터 읽기 시작<br>
        earliest : 가장 예전 오프셋부터 읽기 시작<br>
        none : 커밋이 이후 오프셋부터 읽기 시작, 커밋 기록이 없으면 오류 반환
      </td>
    </tr>
    <tr>
      <td>enable.auto.commit</td>
      <td>
        자동 커밋 여부<br>
        기본값 : true
      </td>
    </tr>
    <tr>
      <td>auto.commit.interval.ms</td>
      <td>
        자동 오프셋 커밋 주기<br>
        기본값 : 5000 (5초)
      </td>
    </tr>
    <tr>
      <td>max.poll.records</td>
      <td>
        poll() 시 반환되는 레코드 개수<br>
        기본값 : 500
      </td>
    </tr>
    <tr>
      <td>session.timeout.ms</td>
      <td>
        컨슈머-브로커 연결 타임아웃 시간<br>
        설정한 시간 내 브로커에 컨슈머의 하트비트가 오지 않으면 리밸런싱 발생<br>
        기본값 : 10000 (10초)
      </td>
    </tr>
    <tr>
      <td>heartbeat.interval.ms</td>
      <td>
        컨슈머가 브로커에게 하트비트 전송 주기<br>
        기본값 : 3000 (3초)
      </td>
    </tr>
    <tr>
      <td>max.poll.interval.ms</td>
      <td>
        poll() 호출 간격의 최대 허용 시간<br>
        리밸런싱 판단 기준 (시간 내 poll 호출이 없으면 컨슈머 세션 종료 후 리밸런싱)<br>
        레코드 처리 속도가 느리면 늘리는게 좋음<br>
        기본값 : 300000 (5분)
      </td>
    </tr>
    <tr>
      <td>isolation.level</td>
      <td>
        트랜잭션 메시지 처리 방식 설정<br>
        트랜잭션 프로듀서가 트랜잭션 단위로 데이터 보낼 경우 사용<br>
        기본값 : read_uncommitted<br><br>
        read_uncommitted : 커밋 전 메시지도 읽음<br>
        read_committed : 커밋 된 메시지만 읽음
      </td>
    </tr>
  </tbody>
</table>

---

## 리밸런스 리스너 설정

### 리밸런스 리스너 정의
```
public class RebalanceListener implements ConsumerRebalanceListener {
  private static final Logger LOGGER = LoggerFactory.getLogger(RebalanceListener.class);

  @Override
  public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
    // 파티션 해제 전 (리밸런싱 발생 전) 동작할 로직
    LOGGER.warn("Partitions are revoked : {}", partitions);
  }

  @Override
  public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
    // 파티션 할당 후 (리밸런싱 발생 후) 동작할 로직
    LOGGER.warn("Partitions are assigned : {}", partitions);
  }
}
```
컨슈머에 파티션 할당/해제 시 동작할 로직을 정의합니다.

### 토픽 구독 시 리밸런스 리스너 전달
```
consumer.subscribe(Arrays.asList(TOPIC_NAME), new RebalanceListener());
```
ConsumerRebalanceListener 인터페이스를 구현한 리밸런스 리스너 클래스를 파라미터로 넘기면 됩니다.

### 파티션 할당 로그 확인
```
[main] WARN com.example.RebalanceListener - Partitions are assigned : [토픽명-파티션번호]
```
컨슈머 애플리케이션 실행 시 로그에서 위와 같이 할당된 파티션을 확인할 수 있습니다.
